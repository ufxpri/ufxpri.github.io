스토리지 간 데이터 이동이 어떻게 가능한지 알아본다

라이프사이클을 사용해서 자동으로 전환이 가능하다.

접두어를 사용하거나 생성자를 기반으로 규칙을 만들 수 있다.

amazon s3 analytics 를 사용하면 통계를 사용해서 데이터를 어떻게 설정할 지 도움을 받을 수 있다.


requester pays (요청자 지불)
버킷 소유자가 모든 비용을 부담하는것으로 배웠다.
하지만 많은 데이터 요청이 발생하면서 소유자가 아닌 요청자가 비용을 부담하도록 할 수 있다.
요청자는 AWS의 인증을 받은 상태여야 한다.


이벤트 알림
오브젝트와 관련된 모든 활동은 이벤트가 발생한다.
이 이벤트를 SNS, SQS, Lambda 에 전달할 수 있다.
이를 위해선 리소스 정책을 설정해야 한다.
IAM Role 을 사용하는게 아닌 SNS 토픽, SQS Queue 혹은 람다 함수에서 엑세스 정책을 정의한다.

모든 이벤트는 amaxon event bridge 를 통해 전달된다.
이 안에서 여러가지 필터 등을 사용할 수 있다.


S3 기본 성능
- 레이턴시 100~200ms
- 3,500 PUT/COPY/POST/DELETE, 5,500 GET/HEAD per second

- 100MB 이상은 멀티파일 권장, 5GB 이상은 반드시 multi file 사용
- S3 Transfer Acceleration: 엣지로케이션을 사용해 더 빠르게 데이터 전송

S3 Byte-Range Fetches
파일이 큰 경우 byte 단위로 파일을 읽을 수 있다. GET 요청을 병렬화 해서 다운로드를 할 수 있는 것 이다.
헤더만 읽을 수 도 있다.


S3 Select & Clacier Select
데이터 검색에 필요한 연산을 줄이는것이 목적
- SQL 문을 사용한 서버사이드 필터링을 사용하여 적은 데이터 사용
- rows & columns 로 필터 가능
- 클라이언트측에서는 적은 비용으로 데이터 필터링 가능
- 400% 속도 향상, 80% 비용 절감
따라서 간단한 필터링은 이걸 권장함


S3 Batch Operations
배치 작업을 수행한다. 사실상 데이터를 관리하는 수단중 거의 모든것을 할 수 있는 방법이다.
- 메타데이터 수정
- 버킷간 데이터 복사
- 암호화 되지 않은 데이터만 골라서 암호화
- ACL 및 tag 수정
- S3 Glacier 에서 데이터 복구
- Lambda function 사용하여 커스텀 작업 수행
배치 작업은 단순 작업 뿐 만 아니라 프로세스 추적 및 알림, 재시도 등을 지원하기 때문에 권장하지 않을수가 없다.
예시로 S3 Inventory 에서 목록을 가져와 S3 Select 로 암호화 안된 파일을 필터링 하고 S3 Batch Operations 로 암호화 작업을 수행하여 결과를 낼 수 있다.

