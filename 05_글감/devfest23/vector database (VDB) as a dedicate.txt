vector database (VDB) as a dedicated service

임베딩에대한 설명을 시작한다.

클로바노트를 사용해봤더니 실험보고서를 만들었더니 b+이 나왔다. 와 이거 진짜다 해서 재미를 느꼈다.

데이터를 임베딩으로 저장한다는 의미는 데이터간의 거리를 만들어 분류를 할 수 있게 되는것이다.

그러나 모든 데이터를 검색한다는것은 너무나 많은 연산을 필요로한다 O(n)
그래서 어떤 방식으로 개선할 수 있을까? k-means 인덱싱시에 백터 공간을 nlist개의 그룹으로 나누어 찾는 방식
차원의 저주 때문에 차원이 늘어날 수록 연산량이 ㅇㅇ청나게 많아지게 된다.

sonic.ai

인덱싱을 해야한다!
인덱싱 전략은 다음과같은것들이 있다.
inverted file
graph based
tree based
+ hash based

벡터공간에서의 tradeoff 는 무엇인가?
인덱스를 만들때, 검색할때 비용은 tradeoff 일 수 밖에 없다.

brute force에 비해서 얼마나 잘 가져오느냐 를 측정하고 조율할 수 밖에 없다.

벡터 인덱싱 전략은 다음과 같은게 있는데

ivf-flat
역방향 인덱싱 - "정보탐색 이론"
벡터 공간에서는 비슷한 군집의 역방향 인덱싱을 만드는것을 의미한다.

ivf-pq
프로덕트 퀀타이제이션
인 메모리에 들고있어여 하는데;;
chat gpt 는 1 million 데이터에 대해 6gb 정도 사용된다고 한다.
많은량의 데이터를 서빙하는데 무리가 있을 수 있다.

hnsw
빌드시간과 인덱스 사이즈에 많이 개선이 이루어짐. 많이 사용되고 있다.
레이어를 만들어서 깊이 들어갈 수록 목표에 가까워진다.

결국 db는?
go - weaviate vaid miluvs _> zilliz
rust - drant lancedb -> pinecone
java - potgre elasticsearch redis - 여기는 시도적인 부분

rag 라고 하는것이 있는데 어딘가에 데이터가 저장되어 있는것을 전달하여 생성
helicopter view
벡터서치엔진을 토해서 가져온 인덱싱을 어떻게 가져올 수 있을까 를 얘기했었다.
scale 한 단위에서 비용을 낮추면서 가치있는 데이터를 전달할 수 있는 시스템이 더욱 중요해지고 있다.

ops 의 인프라가 중요해질 것이다.

벡터db 를 얘기한다면은 논문의 구현체를 구현한 기술이 있는 경우가 많다.
이런경우 saving은 높을 수 있다 그러나 러닝커브가 있을 수 있다.

postgres 에서도 지원을 하고 있다. high serving code 이긴 해서 실제 탐색에서 문제가 발생할 수 있다.

실시간 배치도 있다. gpu에 모두 저장해두고 요청시에 찾는 방법도 있다. sonic ai 꺼다 우리꺼다 ㅎㅎ
dynamic batch

nvidia 에서 cuda toolkit 위에 hnsw 를 구현하기도 한다.

검색과 벡터 데이터베이스는 다르다.
vdb 가 다루고 있는 문제는 일반 데이터베이스가 가지고 있는 무제점들과 탐색 비용 및 시간을 줄이기 위한 것들을 포함하고 있다.

백터의 점진적 색인화의 문제도입하려는 vdb 종류에 따라 연산 패텅이 특이할 수 있기 때문에 잘 보고 선택해야 한다. 어떻게 구현을 하고있는지에 대한 이해가 반드시 필요


메타데이터 필터링을 얼마나 잘 해야할것인가.
대부분의 vdb는 인메모리에서 돌아가는것을 기본으로 작성되어 있다. 그래서 확인이 필요하다.

postgre 익스텐션을 사용할 떄 주의해야할 점을 포함해두었으니 한번 봐라. 최적화 하는 방법을 만들 수 있다.

인프라와 티어링의 비교

alit.ly/sionic ai

blog.sionic.ai
들어가서 확인해보자. 굉장히 좋은 맴버들과 협업하고 있다. 채용중이니 도전해봐도 좋을 것 같다.
